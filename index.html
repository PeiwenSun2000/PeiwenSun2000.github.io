<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Peiwen Sun</title>
  
  <meta name="author" content="Peiwen Sun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Peiwen Sun</name>
		<br>
              </p>
              <p>I am a Researcher at <a href="https://ai.google/research/">BUPT</a>, focused on machine learning for emotion/sentiment understanding and multimodal understanding.  After I graduated from BUPT, I was recommended to the College of artificial intelligence in BUPT for a master's degree. Heading to my PhD in future.
		    </p>
		    <p>
              I have been an intern at Megvii and Tencent to do researches and projects of emotion/sentiment understanding and multimodal understanding.
              </p>
              <p>
              
               
              </p>
              <p style="text-align:center">
                <a href="data/PeiwenSun_CV.pdf">CV</a> &nbsp/&nbsp
    <a href="https://github.com/PeiwenSun2000"> GitHub </a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/PeiwenSun_headshot.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/PeiwenSun_headshot.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<!---
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                2021
                  <ul>

                      <li>Intern at Tencent</li>
                      <li>Facial recognition and emtion/sentiment recognition</li>

                  </ul>
              </p>
              <p>
                2020
                  <ul>

                      <li>Intern at Magvii</li>
                      <li>Facial recognition and emtion/sentiment recognition</li>

                  </ul>
              </p>
            </td>
          </tr>
-->
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <heading>Research</heading>
        
            <p>
      
              My research focuses on person recognition, emtion/sentiment recognition and multi-modal machine learning techniques for video recognition, including the use of sound and text to learn better visual representations. 
            </p>
          </td>
            </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	     <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/2020MCM.png" alt="mvgpt" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://github.com/PeiwenSun2000/2021-MCM-B-Finalist-sharing/blob/main/2100059-paper.pdf">
                    <papertitle>Race Against Fire  </papertitle>
                  </a>
                  <br>
			<b>PeiwenSun</b>, Wenjing Ye, Wenqing Yu
                  <br>
                  	<em>Mathematical Contest In Modeling</em>, 2021
                  <br>
                  <br>
                  	<b>Finalist Award</b> &nbsp 
                  <br>
                  <a href="https://github.com/PeiwenSun2000/2021-MCM-B-Finalist-sharing/blob/main/2100059-paper.pdf">github</a> 
                  <p></p>
                  <p>A modeling scheme for the layout and number of drones to extinguish and monitor wildfires in southern Australia.</p>
                </td>
              </tr>
	     <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/2022fusion.png" alt="mvgpt" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2209.04093.pdf">
                    <papertitle>Learning Audio-Visual embedding for Wild Person Verification  </papertitle>
                  </a>
                  <br>
			<b>PeiwenSun</b>, Shanshan Zhang, Zishan Liu, Yougen Yuan, Taotao Zhang, Honggang Zhang, Pengfei Hu

                  <br>
                  	<em>Arxiv</em>, 2022
                  <br>
                  <br>
                  	<b>Submitted to ICASSP</b> &nbsp 
                  <br>
                  <a href="https://arxiv.org/pdf/2209.04093.pdf">arxiv</a> 
                  <p></p>
                  <p>A Network for multimodel person verification.</p>
                </td>
              </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
